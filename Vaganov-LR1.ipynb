{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59aa4d55-346e-4a20-9b81-31b03137e3aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n",
      "%pylab is deprecated, use %matplotlib inline and import the required libraries.\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4beea9bf-019b-4480-8574-c61c4d39123c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# рабочее пространство нашего датасета\n",
    "workspace = '/home/caruwoga/Documents/nn/letters_ds/'\n",
    "\n",
    "# папки, с которыми будем вести работу\n",
    "folders = ['test/', 'train/']\n",
    "\n",
    "# алфавит, с которым мы работаем\n",
    "alphabet = 'абвгдеёжзийклмнопрстуфхцчшщъыьэюя'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbf162d-d87f-40c3-ae10-519bacf524f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем папки для тестовой и тренировочной выборок\n",
    "os.makedirs(workspace + folders[0])\n",
    "os.makedirs(workspace + folders[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66ccfea-a833-40c7-9019-953b47b32274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создадим подпапки для букв\n",
    "for dataset in range(2):\n",
    "    for letter in alphabet:\n",
    "        os.makedirs(workspace + folders[dataset] + letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5dba661-1aad-4c77-a1fa-3c6ddde3ab6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# сформируем выборки\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "pics_dir = workspace + 'all_letters_image/'\n",
    "\n",
    "for label in range(1, 34):\n",
    "    letter = alphabet[label-1]\n",
    "    \n",
    "    if label < 10:\n",
    "        primary_sym = '0' + str(label)\n",
    "    else:\n",
    "        primary_sym = str(label)\n",
    "\n",
    "    pics_list = []\n",
    "\n",
    "    for file in sorted(os.listdir(pics_dir)):\n",
    "        if file.startswith(primary_sym):\n",
    "            pics_list.append(file)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    test_data = random.sample(pics_list, k=int(0.2 * len(pics_list)))\n",
    "    train_data = list(set(pics_list) - set(test_data))\n",
    "\n",
    "    # 20% в тестовую выборку\n",
    "    for file in test_data:\n",
    "        shutil.move(pics_dir + file, workspace + folders[0] + letter)\n",
    "\n",
    "    # остальное в тренировочную выборку\n",
    "    for file in train_data:\n",
    "        shutil.move(pics_dir + file, workspace + folders[1] + letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a00e99fc-a419-4643-928a-67779bc0a516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# напишем класс для работы с выборками\n",
    "class LettersDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, workspace_path:str):\n",
    "        super().__init__()\n",
    "\n",
    "        self.workspace_path = workspace_path\n",
    "        self.pics_list = [] # список фотографий\n",
    "\n",
    "        for letter in alphabet:\n",
    "            self.pics_list.append(sorted(os.listdir(workspace_path + letter)))\n",
    "        \n",
    "    def __len__(self):\n",
    "        length = 0\n",
    "        for label in range(33):\n",
    "            length += len(self.pics_list[label])\n",
    "        return length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        board = 0\n",
    "        for label in range(33):\n",
    "            board += len(self.pics_list[label])\n",
    "            if idx < board:\n",
    "                class_id = label\n",
    "                break\n",
    "\n",
    "        # смещение\n",
    "        new_idx = idx - (board - len(self.pics_list[class_id]))\n",
    "\n",
    "        img_path = self.workspace_path + alphabet[class_id] + '/' + self.pics_list[class_id][new_idx]\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "\n",
    "        # BGR -> RGB\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, (32, 32))\n",
    "\n",
    "        img = img.astype(np.float32)\n",
    "        img = img / 255.0\n",
    "\n",
    "        img = img.transpose((2, 0, 1))\n",
    "\n",
    "        t_image = torch.from_numpy(img)\n",
    "        t_class_id = torch.tensor(class_id)\n",
    "        \n",
    "        return {'img': t_image, 'label': t_class_id}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b463720d-7fa5-45d9-ac19-b7eae6d527f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создадим выборки\n",
    "train_path = workspace + folders[1]\n",
    "test_path = workspace + folders[0]\n",
    "\n",
    "train = LettersDataset(train_path) # тренировочная\n",
    "test = LettersDataset(test_path) # тестовая"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9b980eb3-23dc-40c3-8d65-c8d01fbaf0ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11352\n",
      "2838\n"
     ]
    }
   ],
   "source": [
    "# количество элементов в тренировочной выборке\n",
    "print(len(train))\n",
    "\n",
    "# количество элементов в тестовой выборке\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2199beb0-630e-4e89-bef4-49bc7ad77564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# есть ли в наличии cuda\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d40a5d02-9962-4311-9640-55003f9536be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ?\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3f0e9a55-6fd2-4df1-b011-1149e3286e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size - количество одновременно обрабатываемых процессором примеров\n",
    "batch_size = 11\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train, batch_size = batch_size,\n",
    "    shuffle = True, num_workers = 2)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test, batch_size = batch_size,\n",
    "    shuffle = True, num_workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "53fb5861-9f8b-42c4-9e81-ef201f0448b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Для преодоления одной эпохи тренировочного набора требуется: 1032.0\n",
      "Для преодоления одной эпохи тестового набора требуется: 258.0\n"
     ]
    }
   ],
   "source": [
    "print(f'Для преодоления одной эпохи тренировочного набора требуется: {len(train) / batch_size}')\n",
    "print(f'Для преодоления одной эпохи тестового набора требуется: {len(test) / batch_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6c81e5aa-0b3f-49b9-9b92-0e3d572f6169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# написанные модели\n",
    "\n",
    "# первая модель\n",
    "class firstNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__() \n",
    "        \n",
    "        # функция активации\n",
    "        self.act = nn.LeakyReLU(0.25) #0.2\n",
    "        \n",
    "        # выбираем наибольшее из двух\n",
    "        self.maxpool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # двумерная свертка\n",
    "        self.conv0 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3)\n",
    "        self.conv1 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size = 3)\n",
    "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size = 2)\n",
    "\n",
    "        # сглаживание\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        # полносвязные слои\n",
    "        self.linear0 = nn.Linear(in_features=512, out_features=128)\n",
    "        self.linear1 = nn.Linear(in_features=128, out_features=128)\n",
    "\n",
    "        # борьба с переобучением\n",
    "        self.drop0 = nn.Dropout(p=0.35)\n",
    "        self.drop1 = nn.Dropout(p=0.25)\n",
    "        self.drop2 = nn.Dropout(p=0.05)\n",
    "\n",
    "        # выходной слой\n",
    "        self.out = nn.Linear(in_features=128, out_features=33)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # [3, 32, 32] \n",
    "        out = self.conv0(x)\n",
    "        out = self.act(out)\n",
    "        #print(out.shape) # [32, 30, 30]        \n",
    "        out = self.maxpool(out)\n",
    "        #print(out.shape) # [32, 15, 15]\n",
    "        out = self.conv1(out)\n",
    "        out = self.act(out)\n",
    "        out = self.drop2(out)\n",
    "        out = self.maxpool(out)\n",
    "        #print(out.shape) # [64, 6, 6]\n",
    "        out = self.conv2(out)\n",
    "        out = self.act(out)\n",
    "        out = self.maxpool(out)\n",
    "        #print(out.shape) # [128, 2, 2]\n",
    "        out = self.flatten(out)\n",
    "        out = self.linear0(out)\n",
    "        out = self.act(out)\n",
    "        out = self.drop0(out)\n",
    "        out = self.linear1(out)\n",
    "        out = self.drop1(out)\n",
    "        out = self.out(out)\n",
    "        return out\n",
    "\n",
    "# вторая модель\n",
    "class paddingNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.act = nn.LeakyReLU(0.35)\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.conv0 = nn.Conv2d(in_channels=3, out_channels=512, kernel_size=3, padding=2)\n",
    "        self.conv1 = nn.Conv2d(in_channels=512, out_channels=256, kernel_size=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=256, out_channels=128, kernel_size=2)\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.linear0 = nn.Linear(in_features=2048, out_features=1024)\n",
    "        self.linear1 = nn.Linear(in_features=1024, out_features=512)\n",
    "        self.linear2 = nn.Linear(in_features=512, out_features=256)\n",
    "\n",
    "        self.drop0 = nn.Dropout(p=0.3)\n",
    "        self.drop1 = nn.Dropout(p=0.2)\n",
    "\n",
    "        self.out = nn.Linear(in_features=256, out_features=33)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv0(x)\n",
    "        out = self.act(out)\n",
    "        out = self.maxpool(out)\n",
    "        out = self.drop0(out)\n",
    "        out = self.conv1(out)\n",
    "        out = self.act(out)\n",
    "        out = self.maxpool(out)\n",
    "        out = self.drop1(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.act(out)\n",
    "        out = self.maxpool(out)\n",
    "        out = self.flatten(out)\n",
    "        out = self.linear0(out)\n",
    "        out = self.act(out)\n",
    "        out = self.linear1(out)\n",
    "        out = self.act(out)\n",
    "        out = self.drop1(out)\n",
    "        out = self.linear2(out)\n",
    "        out = self.out(out)\n",
    "        return out\n",
    "\n",
    "# третья модель\n",
    "class TinyNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.act = nn.LeakyReLU(0.15)\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.conv0 = nn.Conv2d(in_channels=3, out_channels=512, kernel_size=4)\n",
    "        self.conv1 = nn.Conv2d(in_channels=512, out_channels=64, kernel_size=3)\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.linear0 = nn.Linear(in_features=9216, out_features=800)\n",
    "\n",
    "        self.drop0 = nn.Dropout(p=0.2)\n",
    "\n",
    "        self.out = nn.Linear(in_features=800, out_features=33)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv0(x)\n",
    "        out = self.act(out)\n",
    "        out = self.maxpool(out)\n",
    "        out = self.conv1(out)\n",
    "        out = self.act(out)\n",
    "        out = self.flatten(out)\n",
    "        out = self.linear0(out)\n",
    "        out = self.act(out)\n",
    "        out = self.drop0(out)\n",
    "        out = self.out(out)\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7a9b0571-d5d6-449c-bcfb-696336acc6cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "firstNet(\n",
       "  (act): LeakyReLU(negative_slope=0.25)\n",
       "  (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(64, 128, kernel_size=(2, 2), stride=(1, 1))\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear0): Linear(in_features=512, out_features=128, bias=True)\n",
       "  (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (drop0): Dropout(p=0.35, inplace=False)\n",
       "  (drop1): Dropout(p=0.25, inplace=False)\n",
       "  (drop2): Dropout(p=0.05, inplace=False)\n",
       "  (out): Linear(in_features=128, out_features=33, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = firstNet()\n",
    "\n",
    "#model = TinyNet()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "63ef0486-f853-4b09-9367-49020963c7f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Число параметров в модели: 138,721\n"
     ]
    }
   ],
   "source": [
    "# подсчитаем число параметров\n",
    "params_num = 0\n",
    "for x in model.parameters():\n",
    "    params_num += len(torch.flatten(x))\n",
    "\n",
    "print(f'Число параметров в модели: {params_num:,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "765ee696-0879-4841-94bc-318dadd5d0fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape: torch.Size([11, 3, 32, 32])\n",
      "after network shape: torch.Size([11, 33])\n"
     ]
    }
   ],
   "source": [
    "for sample in train_loader:\n",
    "    img = sample['img'].to(device)\n",
    "    label = sample['label']\n",
    "    print(f'input shape: {img.shape}')\n",
    "    print(f'after network shape: {model(img).shape}')\n",
    "    model(img)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "05af365e-0345-451f-bca7-77b5c2538d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция потерь\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# оптимизатор\n",
    "# lr - скорость обучения\n",
    "# lr = 0.00003\n",
    "\n",
    "lr = 0.001\n",
    "#lr = 0.0005 # first model \n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "292764e1-5f59-421f-90cf-ef0887a65538",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model):\n",
    "    model.train(True) # модель находится в режиме обучения\n",
    "    \n",
    "    current_loss = 0.0\n",
    "    current_accuracy = 0.0\n",
    "\n",
    "    sum_loss = 0.0\n",
    "\n",
    "    # номер пакета и данные\n",
    "    for batch_index, sample in enumerate(train_loader):\n",
    "        img = sample['img'].to(device)\n",
    "        label = sample['label'].to(device)\n",
    "\n",
    "        # если есть ненулевые значения для градиентов, зануляем их ?\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # выходные данные модели для этого пакета\n",
    "        # форма: [batch_size, 33]\n",
    "        out = model(img) \n",
    "        \n",
    "        # сумма значений меток = предсказание для этого изображения\n",
    "        correct = torch.sum(label == torch.argmax(out, dim=1)).item() \n",
    "\n",
    "        # точность\n",
    "        current_accuracy += correct / batch_size\n",
    "        \n",
    "        # сравниваем значения выходных данных с истинными метками\n",
    "        loss = loss_fn(out, label)\n",
    "        current_loss += loss.item()\n",
    "        \n",
    "        # обратно идем - обратное распространение\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # проверяем в каждых 500 пакетах средние потери\n",
    "        if batch_index % 500 == 499: \n",
    "            avg_loss = current_loss / 500\n",
    "            sum_loss += current_loss\n",
    "            avg_accuracy = (current_accuracy / 500) * 100\n",
    "\n",
    "            print('Batch {0}, loss: {1:.3f}, Accuracy: {2:.1f}%'.format(batch_index+1,\n",
    "                                                                       avg_loss, avg_accuracy))\n",
    "            \n",
    "            current_loss = 0.0\n",
    "            current_accuracy = 0.0\n",
    "    sum_loss = sum_loss / len(train_loader)\n",
    "    \n",
    "    return sum_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "87c673a7-186c-4ca3-a0d9-290bbb84a123",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_one_epoch(model):\n",
    "    model.train(False) # модель находится в режиме оценки\n",
    "\n",
    "    current_loss = 0.0\n",
    "    current_accuracy = 0.0\n",
    "\n",
    "    for index, sample in enumerate(test_loader):\n",
    "        img = sample['img'].to(device)\n",
    "        label = sample['label'].to(device)\n",
    "\n",
    "        # об этом не беспокоимся, т.к. ничего не обучаем\n",
    "        with torch.no_grad():\n",
    "            out = model(img)\n",
    "            correct = torch.sum(label == torch.argmax(out, dim=1)).item() \n",
    "            current_accuracy += correct / batch_size\n",
    "            loss = loss_fn(out, label)\n",
    "            current_loss += loss.item()\n",
    "\n",
    "    avg_loss = current_loss / len(test_loader)\n",
    "    avg_accuracy = (current_accuracy / len(test_loader)) * 100\n",
    "\n",
    "    print('Test loss: {0:.3f}, Test Accuracy: {1:.1f}%'.format(avg_loss, avg_accuracy))\n",
    "    print('**********************************************')\n",
    "    print()\n",
    "\n",
    "    return avg_loss, avg_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "20635def-8dc5-4ea1-821c-5134b1bc4cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "\n",
      "Batch 500, loss: 3.459, Accuracy: 4.6%\n",
      "Batch 1000, loss: 3.279, Accuracy: 8.3%\n",
      "Test loss: 2.847, Test Accuracy: 18.0%\n",
      "**********************************************\n",
      "\n",
      "Epoch: 2\n",
      "\n",
      "Batch 500, loss: 2.624, Accuracy: 22.7%\n",
      "Batch 1000, loss: 2.044, Accuracy: 39.6%\n",
      "Test loss: 1.621, Test Accuracy: 52.7%\n",
      "**********************************************\n",
      "\n",
      "Epoch: 3\n",
      "\n",
      "Batch 500, loss: 1.644, Accuracy: 51.5%\n",
      "Batch 1000, loss: 1.425, Accuracy: 57.8%\n",
      "Test loss: 1.198, Test Accuracy: 64.6%\n",
      "**********************************************\n",
      "\n",
      "Epoch: 4\n",
      "\n",
      "Batch 500, loss: 1.256, Accuracy: 62.5%\n",
      "Batch 1000, loss: 1.136, Accuracy: 66.2%\n",
      "Test loss: 0.982, Test Accuracy: 71.9%\n",
      "**********************************************\n",
      "\n",
      "Epoch: 5\n",
      "\n",
      "Batch 500, loss: 0.995, Accuracy: 70.3%\n",
      "Batch 1000, loss: 0.996, Accuracy: 70.1%\n",
      "Test loss: 0.900, Test Accuracy: 73.0%\n",
      "**********************************************\n",
      "\n",
      "Epoch: 6\n",
      "\n",
      "Batch 500, loss: 0.869, Accuracy: 73.1%\n",
      "Batch 1000, loss: 0.894, Accuracy: 73.1%\n",
      "Test loss: 0.824, Test Accuracy: 76.5%\n",
      "**********************************************\n",
      "\n",
      "Epoch: 7\n",
      "\n",
      "Batch 500, loss: 0.775, Accuracy: 75.7%\n",
      "Batch 1000, loss: 0.758, Accuracy: 76.7%\n",
      "Test loss: 0.797, Test Accuracy: 76.8%\n",
      "**********************************************\n",
      "\n",
      "Epoch: 8\n",
      "\n",
      "Batch 500, loss: 0.733, Accuracy: 77.6%\n",
      "Batch 1000, loss: 0.703, Accuracy: 78.5%\n",
      "Test loss: 0.700, Test Accuracy: 79.8%\n",
      "**********************************************\n",
      "\n",
      "Epoch: 9\n",
      "\n",
      "Batch 500, loss: 0.628, Accuracy: 80.4%\n",
      "Batch 1000, loss: 0.688, Accuracy: 79.4%\n",
      "Test loss: 0.652, Test Accuracy: 80.7%\n",
      "**********************************************\n",
      "\n",
      "Epoch: 10\n",
      "\n",
      "Batch 500, loss: 0.562, Accuracy: 81.8%\n",
      "Batch 1000, loss: 0.617, Accuracy: 81.3%\n",
      "Test loss: 0.715, Test Accuracy: 79.4%\n",
      "**********************************************\n",
      "\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "tr_los, ts_los, ts_acc = [], [], []\n",
    "\n",
    "for epoch_index in range(num_epochs):\n",
    "    print(f'Epoch: {epoch_index + 1}\\n')\n",
    "\n",
    "    train_losses = train_one_epoch(model)\n",
    "    test_losses, test_accuracies = test_one_epoch(model)\n",
    "    \n",
    "    tr_los.append(train_losses)\n",
    "    ts_los.append(test_losses)\n",
    "    ts_acc.append(test_accuracies)\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c29585b5-bf01-4c45-9d35-d4133a87ed4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(test_accuracy, test_loss, train_loss):\n",
    "    epochs = range(1, num_epochs + 1)\n",
    "    plt.figure(figsize(12, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    \n",
    "    plt.plot(epochs, train_loss, 'bo-', label='Training loss')\n",
    "    plt.plot(epochs, test_loss, 'ro-', label='Test loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, test_accuracy, 'go-', label='Test accuracy')\n",
    "    plt.title('Validation accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4f79d302-1526-42fb-8040-04a6ce898c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(ts_acc, ts_los, tr_los)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ffefb6e1-1420-412a-9ee9-1778c3258bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, num_epochs, train_loader, valid_loader, optimizer, criterion):\n",
    "    train_loss_avg = []\n",
    "    valid_loss_avg = []\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "\n",
    "        \n",
    "        for index, sample in enumerate(train_loader):\n",
    "            img = sample['img'].to(device)\n",
    "            label = sample['label'].to(device)\n",
    "\n",
    "            # об этом не беспокоимся, т.к. ничего не обучаем\n",
    "            with torch.no_grad():\n",
    "                out = model(img)\n",
    "                correct = torch.sum(label == torch.argmax(out, dim=1)).item() \n",
    "                current_accuracy += correct / batch_size\n",
    "                loss = loss_fn(out, label)\n",
    "                current_loss += loss.item()\n",
    "\n",
    "        avg_loss = current_loss / len(test_loader)\n",
    "        avg_accuracy = (current_accuracy / len(test_loader)) * 100\n",
    "    \n",
    "        return model, avg_loss, avg_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7eb5fe4d-7cc1-4bd8-91bc-a66b0ca729e2",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'current_accuracy' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[108], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m lossFunc \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[1;32m      9\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mSGD(model_prepaded\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0004\u001b[39m, weight_decay \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.005\u001b[39m, momentum \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.9\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m transfer_model, transfer_train_loss_avg, transfer_validate_loss_avg \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_prepaded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlossFunc\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[107], line 17\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, num_epochs, train_loader, valid_loader, optimizer, criterion)\u001b[0m\n\u001b[1;32m     15\u001b[0m out \u001b[38;5;241m=\u001b[39m model(img)\n\u001b[1;32m     16\u001b[0m correct \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(label \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(out, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mitem() \n\u001b[0;32m---> 17\u001b[0m current_accuracy \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m correct \u001b[38;5;241m/\u001b[39m batch_size\n\u001b[1;32m     18\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(out, label)\n\u001b[1;32m     19\u001b[0m current_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'current_accuracy' referenced before assignment"
     ]
    }
   ],
   "source": [
    "import torchvision as tv\n",
    "\n",
    "model_prepaded = tv.models.resnet34(weights=tv.models.ResNet34_Weights.IMAGENET1K_V1).to(device)\n",
    "\n",
    "num_ftrs = model_prepaded.fc.in_features\n",
    "\n",
    "model_prepaded.fc = nn.Linear(num_ftrs, 33).to(device)\n",
    "lossFunc = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model_prepaded.parameters(), lr=0.0004, weight_decay = 0.005, momentum = 0.9)\n",
    "\n",
    "transfer_model, transfer_train_loss_avg, transfer_validate_loss_avg = train_model(model_prepaded, num_epochs, train_loader, test_loader, optimizer, lossFunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9fdb85-541c-4a5b-bd8c-ce17b47e3d0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
